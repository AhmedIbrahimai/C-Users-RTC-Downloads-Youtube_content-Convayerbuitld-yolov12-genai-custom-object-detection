{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8ed39c6b-f2fd-40da-bae9-52f1284b902d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.6.1 (SDL 2.28.4, Python 3.11.7)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n",
      "\n",
      "0: 384x640 1 object, 90.7ms\n",
      "Speed: 8.1ms preprocess, 90.7ms inference, 363.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 33.4ms\n",
      "Speed: 2.0ms preprocess, 33.4ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.0ms\n",
      "Speed: 3.9ms preprocess, 24.0ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 25.6ms\n",
      "Speed: 3.9ms preprocess, 25.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.0ms\n",
      "Speed: 3.4ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 50.3ms\n",
      "Speed: 2.4ms preprocess, 50.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 30.8ms\n",
      "Speed: 3.0ms preprocess, 30.8ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 27.6ms\n",
      "Speed: 2.0ms preprocess, 27.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 23.2ms\n",
      "Speed: 1.9ms preprocess, 23.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.6ms\n",
      "Speed: 2.7ms preprocess, 24.6ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 28.0ms\n",
      "Speed: 3.2ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 32.7ms\n",
      "Speed: 2.9ms preprocess, 32.7ms inference, 6.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 31.4ms\n",
      "Speed: 2.1ms preprocess, 31.4ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 23.2ms\n",
      "Speed: 2.8ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 22.9ms\n",
      "Speed: 2.0ms preprocess, 22.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 38.8ms\n",
      "Speed: 2.3ms preprocess, 38.8ms inference, 3.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 31.0ms\n",
      "Speed: 3.0ms preprocess, 31.0ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 33.2ms\n",
      "Speed: 2.9ms preprocess, 33.2ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 27.5ms\n",
      "Speed: 3.4ms preprocess, 27.5ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 23.6ms\n",
      "Speed: 2.0ms preprocess, 23.6ms inference, 4.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 25.4ms\n",
      "Speed: 2.0ms preprocess, 25.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 27.2ms\n",
      "Speed: 2.7ms preprocess, 27.2ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 25.0ms\n",
      "Speed: 4.1ms preprocess, 25.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.5ms\n",
      "Speed: 1.8ms preprocess, 26.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 30.0ms\n",
      "Speed: 3.8ms preprocess, 30.0ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 28.7ms\n",
      "Speed: 2.6ms preprocess, 28.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.6ms\n",
      "Speed: 3.8ms preprocess, 24.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 27.6ms\n",
      "Speed: 4.4ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 49.1ms\n",
      "Speed: 2.2ms preprocess, 49.1ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 47.6ms\n",
      "Speed: 3.4ms preprocess, 47.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 47.5ms\n",
      "Speed: 3.5ms preprocess, 47.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 34.4ms\n",
      "Speed: 4.1ms preprocess, 34.4ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 32.4ms\n",
      "Speed: 4.9ms preprocess, 32.4ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 30.3ms\n",
      "Speed: 4.8ms preprocess, 30.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 30.3ms\n",
      "Speed: 2.5ms preprocess, 30.3ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 29.1ms\n",
      "Speed: 2.3ms preprocess, 29.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.0ms\n",
      "Speed: 3.2ms preprocess, 26.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 29.5ms\n",
      "Speed: 1.8ms preprocess, 29.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 33.1ms\n",
      "Speed: 3.4ms preprocess, 33.1ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 31.7ms\n",
      "Speed: 2.3ms preprocess, 31.7ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 31.7ms\n",
      "Speed: 3.1ms preprocess, 31.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 22.2ms\n",
      "Speed: 2.0ms preprocess, 22.2ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 37.1ms\n",
      "Speed: 3.1ms preprocess, 37.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 47.5ms\n",
      "Speed: 2.0ms preprocess, 47.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 22.1ms\n",
      "Speed: 2.0ms preprocess, 22.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 29.2ms\n",
      "Speed: 2.9ms preprocess, 29.2ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 112.0ms\n",
      "Speed: 3.3ms preprocess, 112.0ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 108.6ms\n",
      "Speed: 3.5ms preprocess, 108.6ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 100.1ms\n",
      "Speed: 4.8ms preprocess, 100.1ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 61.1ms\n",
      "Speed: 3.9ms preprocess, 61.1ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 19.6ms\n",
      "Speed: 2.3ms preprocess, 19.6ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.4ms\n",
      "Speed: 2.0ms preprocess, 24.4ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 21.6ms\n",
      "Speed: 2.4ms preprocess, 21.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.5ms\n",
      "Speed: 1.7ms preprocess, 26.5ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 21.5ms\n",
      "Speed: 1.9ms preprocess, 21.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.9ms\n",
      "Speed: 1.9ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.1ms\n",
      "Speed: 2.4ms preprocess, 24.1ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 30.0ms\n",
      "Speed: 2.2ms preprocess, 30.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.0ms\n",
      "Speed: 2.1ms preprocess, 24.0ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 23.7ms\n",
      "Speed: 1.8ms preprocess, 23.7ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 35.1ms\n",
      "Speed: 4.5ms preprocess, 35.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 22.3ms\n",
      "Speed: 2.2ms preprocess, 22.3ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 21.5ms\n",
      "Speed: 1.8ms preprocess, 21.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 19.5ms\n",
      "Speed: 1.6ms preprocess, 19.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 20.7ms\n",
      "Speed: 1.6ms preprocess, 20.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 26.8ms\n",
      "Speed: 1.7ms preprocess, 26.8ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 19.3ms\n",
      "Speed: 3.3ms preprocess, 19.3ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 27.4ms\n",
      "Speed: 2.1ms preprocess, 27.4ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.3ms\n",
      "Speed: 6.0ms preprocess, 24.3ms inference, 7.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 32.7ms\n",
      "Speed: 4.3ms preprocess, 32.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.5ms\n",
      "Speed: 3.2ms preprocess, 26.5ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 30.4ms\n",
      "Speed: 2.9ms preprocess, 30.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.7ms\n",
      "Speed: 1.7ms preprocess, 22.7ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 21.7ms\n",
      "Speed: 1.6ms preprocess, 21.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 21.2ms\n",
      "Speed: 1.9ms preprocess, 21.2ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.2ms\n",
      "Speed: 2.5ms preprocess, 26.2ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 21.3ms\n",
      "Speed: 1.7ms preprocess, 21.3ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 38.7ms\n",
      "Speed: 2.9ms preprocess, 38.7ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 31.0ms\n",
      "Speed: 3.4ms preprocess, 31.0ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.3ms\n",
      "Speed: 1.8ms preprocess, 24.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 29.8ms\n",
      "Speed: 2.1ms preprocess, 29.8ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 21.3ms\n",
      "Speed: 2.0ms preprocess, 21.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 27.6ms\n",
      "Speed: 3.0ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.7ms\n",
      "Speed: 1.9ms preprocess, 22.7ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.8ms\n",
      "Speed: 1.6ms preprocess, 25.8ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.3ms\n",
      "Speed: 2.7ms preprocess, 22.3ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 23.4ms\n",
      "Speed: 1.9ms preprocess, 23.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.8ms\n",
      "Speed: 2.8ms preprocess, 22.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 29.2ms\n",
      "Speed: 4.3ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.7ms\n",
      "Speed: 3.6ms preprocess, 22.7ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.3ms\n",
      "Speed: 1.8ms preprocess, 22.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 23.4ms\n",
      "Speed: 1.9ms preprocess, 23.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.4ms\n",
      "Speed: 1.8ms preprocess, 22.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 22.5ms\n",
      "Speed: 1.7ms preprocess, 22.5ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.0ms\n",
      "Speed: 2.3ms preprocess, 24.0ms inference, 5.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 29.5ms\n",
      "Speed: 2.6ms preprocess, 29.5ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.0ms\n",
      "Speed: 2.5ms preprocess, 24.0ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.9ms\n",
      "Speed: 6.0ms preprocess, 26.9ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.4ms\n",
      "Speed: 2.6ms preprocess, 24.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.9ms\n",
      "Speed: 2.8ms preprocess, 24.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.3ms\n",
      "Speed: 3.8ms preprocess, 24.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.2ms\n",
      "Speed: 1.8ms preprocess, 25.2ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 36.7ms\n",
      "Speed: 3.1ms preprocess, 36.7ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.2ms\n",
      "Speed: 1.9ms preprocess, 24.2ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.3ms\n",
      "Speed: 3.1ms preprocess, 24.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.4ms\n",
      "Speed: 1.6ms preprocess, 24.4ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.6ms\n",
      "Speed: 2.3ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.8ms\n",
      "Speed: 2.2ms preprocess, 24.8ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.6ms\n",
      "Speed: 3.4ms preprocess, 24.6ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.7ms\n",
      "Speed: 1.9ms preprocess, 24.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 41.5ms\n",
      "Speed: 1.8ms preprocess, 41.5ms inference, 4.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 27.0ms\n",
      "Speed: 3.0ms preprocess, 27.0ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 object, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 3.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 24.9ms\n",
      "Speed: 1.8ms preprocess, 24.9ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.3ms\n",
      "Speed: 1.9ms preprocess, 25.3ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.4ms\n",
      "Speed: 1.8ms preprocess, 25.4ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.3ms\n",
      "Speed: 1.6ms preprocess, 25.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.4ms\n",
      "Speed: 2.1ms preprocess, 25.4ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.2ms\n",
      "Speed: 1.6ms preprocess, 25.2ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 29.5ms\n",
      "Speed: 3.3ms preprocess, 29.5ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 33.3ms\n",
      "Speed: 2.3ms preprocess, 33.3ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.6ms\n",
      "Speed: 1.7ms preprocess, 25.6ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.1ms\n",
      "Speed: 2.1ms preprocess, 26.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 2.2ms preprocess, 26.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.9ms\n",
      "Speed: 2.1ms preprocess, 25.9ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.1ms\n",
      "Speed: 2.1ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 25.9ms\n",
      "Speed: 2.8ms preprocess, 25.9ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 42.6ms\n",
      "Speed: 4.2ms preprocess, 42.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 29.4ms\n",
      "Speed: 1.8ms preprocess, 29.4ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.8ms\n",
      "Speed: 2.3ms preprocess, 26.8ms inference, 4.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.9ms\n",
      "Speed: 2.2ms preprocess, 26.9ms inference, 4.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.6ms\n",
      "Speed: 2.1ms preprocess, 26.6ms inference, 5.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.8ms\n",
      "Speed: 2.7ms preprocess, 26.8ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 2.0ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 3.5ms preprocess, 26.4ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 34.7ms\n",
      "Speed: 1.9ms preprocess, 34.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.8ms\n",
      "Speed: 2.5ms preprocess, 26.8ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 29.9ms\n",
      "Speed: 2.9ms preprocess, 29.9ms inference, 3.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 28.1ms\n",
      "Speed: 2.6ms preprocess, 28.1ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 2.1ms preprocess, 26.4ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 1.6ms preprocess, 26.4ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 1.8ms preprocess, 26.3ms inference, 1.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.5ms\n",
      "Speed: 3.1ms preprocess, 26.5ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 27.1ms\n",
      "Speed: 1.8ms preprocess, 27.1ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 2.1ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.6ms\n",
      "Speed: 2.6ms preprocess, 26.6ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.1ms\n",
      "Speed: 1.8ms preprocess, 26.1ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 48.3ms\n",
      "Speed: 4.1ms preprocess, 48.3ms inference, 3.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 27.8ms\n",
      "Speed: 2.2ms preprocess, 27.8ms inference, 4.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.2ms\n",
      "Speed: 1.7ms preprocess, 26.2ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.2ms\n",
      "Speed: 2.8ms preprocess, 26.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.6ms\n",
      "Speed: 2.3ms preprocess, 26.6ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.5ms\n",
      "Speed: 2.0ms preprocess, 26.5ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 41.0ms\n",
      "Speed: 2.0ms preprocess, 41.0ms inference, 3.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 1.8ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 27.1ms\n",
      "Speed: 2.6ms preprocess, 27.1ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 32.2ms\n",
      "Speed: 1.7ms preprocess, 32.2ms inference, 3.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 33.6ms\n",
      "Speed: 2.8ms preprocess, 33.6ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 33.1ms\n",
      "Speed: 3.1ms preprocess, 33.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 28.9ms\n",
      "Speed: 2.2ms preprocess, 28.9ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.6ms\n",
      "Speed: 1.6ms preprocess, 26.6ms inference, 2.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 27.0ms\n",
      "Speed: 2.9ms preprocess, 27.0ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.6ms\n",
      "Speed: 1.8ms preprocess, 26.6ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.7ms\n",
      "Speed: 2.0ms preprocess, 26.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.7ms\n",
      "Speed: 1.7ms preprocess, 26.7ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 2.2ms preprocess, 26.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.2ms\n",
      "Speed: 2.1ms preprocess, 26.2ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 27.3ms\n",
      "Speed: 1.7ms preprocess, 27.3ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 2.3ms preprocess, 26.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.5ms\n",
      "Speed: 1.9ms preprocess, 26.5ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 2.7ms preprocess, 26.3ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.9ms\n",
      "Speed: 1.8ms preprocess, 26.9ms inference, 3.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 1.9ms preprocess, 26.4ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.4ms\n",
      "Speed: 3.1ms preprocess, 26.4ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 31.7ms\n",
      "Speed: 2.0ms preprocess, 31.7ms inference, 4.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.7ms\n",
      "Speed: 3.1ms preprocess, 26.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.7ms\n",
      "Speed: 3.6ms preprocess, 26.7ms inference, 4.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.2ms\n",
      "Speed: 2.4ms preprocess, 26.2ms inference, 2.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 37.7ms\n",
      "Speed: 1.9ms preprocess, 37.7ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 40.7ms\n",
      "Speed: 1.9ms preprocess, 40.7ms inference, 6.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 1.6ms preprocess, 26.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 2.0ms preprocess, 26.3ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 38.1ms\n",
      "Speed: 3.6ms preprocess, 38.1ms inference, 4.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.2ms\n",
      "Speed: 1.8ms preprocess, 26.2ms inference, 2.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 objects, 26.3ms\n",
      "Speed: 1.9ms preprocess, 26.3ms inference, 2.3ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "import base64\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import pygame  # For playing alert sounds\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client for OpenRouter.ai\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"\",  # Replace with your OpenRouter API key\n",
    ")\n",
    "\n",
    "class PackageDetectionProcessor:\n",
    "    def __init__(self, video_file, yolo_model_path=\"best.pt\"):\n",
    "        \"\"\"Initialize package detection processor for conveyor belt monitoring.\"\"\"\n",
    "        try:\n",
    "            self.yolo_model = YOLO(yolo_model_path)\n",
    "            self.names = self.yolo_model.names\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading YOLO model: {e}\")\n",
    "\n",
    "        self.cap = cv2.VideoCapture(video_file)\n",
    "        if not self.cap.isOpened():\n",
    "            raise FileNotFoundError(\"Error: Could not open video file.\")\n",
    "\n",
    "        self.processed_track_ids = set()\n",
    "        self.current_date = time.strftime(\"%Y-%m-%d\")\n",
    "        self.output_filename = f\"package_data_{self.current_date}.txt\"\n",
    "        self.cropped_images_folder = \"cropped_packages\"\n",
    "        os.makedirs(self.cropped_images_folder, exist_ok=True)\n",
    "\n",
    "        # Detection line parameters\n",
    "        self.cx1 = 416  # X-position of the vertical line\n",
    "        self.offset = 6  # Offset for detection tolerance\n",
    "\n",
    "        # Sound alert setup\n",
    "        pygame.mixer.init()\n",
    "        self.alert_sound = \"alert.mp3\"  # Ensure this file exists in the same directory\n",
    "        self.sound_playing = False  # Track sound state\n",
    "        \n",
    "        # Initialize report file\n",
    "        if not os.path.exists(self.output_filename):\n",
    "            with open(self.output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(\"Timestamp | Track ID | Package Type | Front Open | Damage Condition\\n\")\n",
    "                file.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    def play_alert(self):\n",
    "        \"\"\"Play an alert sound if it's not already playing.\"\"\"\n",
    "        if not self.sound_playing:\n",
    "            pygame.mixer.music.load(self.alert_sound)\n",
    "            pygame.mixer.music.play(-1)  # Loop indefinitely\n",
    "            self.sound_playing = True\n",
    "\n",
    "    def stop_alert(self):\n",
    "        \"\"\"Stop the alert sound if playing.\"\"\"\n",
    "        if self.sound_playing:\n",
    "            pygame.mixer.music.stop()\n",
    "            self.sound_playing = False\n",
    "\n",
    "    def analyze_image_with_openai(self, image_path):\n",
    "        \"\"\"Analyze the package image using OpenAI via OpenRouter.ai.\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as img_file:\n",
    "                base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "            # Prepare the prompt for OpenAI\n",
    "            prompt = \"\"\"\n",
    "            Analyze the given image of a package and extract the following details:\n",
    "            \n",
    "            - **Box Front Open (Yes/No)**\n",
    "            - **Damage Condition (Yes/No)**\n",
    "            \n",
    "            Return results in table format only:\n",
    "            | Package Type (box) | Box Front Flap Open (Yes/No) | Damage Condition (Yes/No) |\n",
    "            |--------------------|----------------------------|--------------------------|\n",
    "            \"\"\"\n",
    "\n",
    "            # Send the request to OpenAI via OpenRouter.ai\n",
    "            completion = client.chat.completions.create(\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"<YOUR_SITE_URL>\",  # Optional. Replace with your site URL.\n",
    "                    \"X-Title\": \"<YOUR_SITE_NAME>\",     # Optional. Replace with your site name.\n",
    "                },\n",
    "                extra_body={},\n",
    "                model=\"google/gemini-2.0-flash-lite-preview-02-05:free\",  # Replace with your preferred model\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response_text = completion.choices[0].message.content.strip()\n",
    "            return response_text\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error invoking OpenAI model: {e}\")\n",
    "            return \"Error processing image.\"\n",
    "\n",
    "    def process_crop_image(self, image, track_id):\n",
    "        \"\"\"Save and analyze cropped package images.\"\"\"\n",
    "        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        image_filename = os.path.join(self.cropped_images_folder, f\"package_{track_id}_{timestamp}.jpg\")\n",
    "        cv2.imwrite(image_filename, image)\n",
    "\n",
    "        response_content = self.analyze_image_with_openai(image_filename)\n",
    "        extracted_data = response_content.split(\"\\n\")[2:]\n",
    "\n",
    "        alert_triggered = False  # Flag to track if an alert is needed\n",
    "        \n",
    "        if extracted_data:\n",
    "            with open(self.output_filename, \"a\", encoding=\"utf-8\") as file:\n",
    "                for row in extracted_data:\n",
    "                    if \"--------------\" in row or not row.strip():\n",
    "                        continue\n",
    "                    values = [col.strip() for col in row.split(\"|\")[1:-1]]\n",
    "                    if len(values) == 3:\n",
    "                        package_type, box_open, damage_status = values\n",
    "                        file.write(f\"{timestamp} | Track ID: {track_id} | {package_type} | {box_open} | {damage_status}\\n\")\n",
    "                        \n",
    "                        if box_open.lower() == \"yes\":\n",
    "                            alert_triggered = True  # Trigger alert\n",
    "\n",
    "        if alert_triggered:\n",
    "            self.play_alert()\n",
    "        else:\n",
    "            self.stop_alert()\n",
    "\n",
    "    def crop_and_process(self, frame, box, track_id):\n",
    "        \"\"\"Crop and process detected packages.\"\"\"\n",
    "        if track_id in self.processed_track_ids:\n",
    "            return  \n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cropped_image = frame[y1:y2, x1:x2]\n",
    "        self.processed_track_ids.add(track_id)\n",
    "        threading.Thread(target=self.process_crop_image, args=(cropped_image, track_id), daemon=True).start()\n",
    "\n",
    "    def process_video_frame(self, frame):\n",
    "        \"\"\"Process each video frame to detect and analyze packages.\"\"\"\n",
    "        frame = cv2.resize(frame, (1020, 600))\n",
    "        results = self.yolo_model.track(frame, persist=True)\n",
    "\n",
    "        if results and results[0].boxes is not None:\n",
    "            boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist() if results[0].boxes.id is not None else [-1] * len(boxes)\n",
    "\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cx = (x1 + x2) // 2 \n",
    "                if self.cx1 - self.offset < cx < self.cx1 + self.offset:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "                    cvzone.putTextRect(frame, f\"ID: {track_id}\", (x2, y2), 1, 1)\n",
    "                    self.crop_and_process(frame, box, track_id)\n",
    "        return frame\n",
    "\n",
    "\n",
    "    def start_processing(self):\n",
    "\n",
    "        \"\"\"Start video processing.\"\"\"\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                self.stop_alert()\n",
    "                break\n",
    "            frame = self.process_video_frame(frame)\n",
    "            cv2.line(frame, (416, 2), (416, 599), (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Package Detection\", frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "        self.cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_file = \"co.mp4\"\n",
    "    processor = PackageDetectionProcessor(video_file)\n",
    "    processor.start_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ded2ff5-ede6-464e-b95e-f000fb524f10",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'os' has no attribute 'maked'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 215\u001b[0m\n\u001b[0;32m    213\u001b[0m video_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mco.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    214\u001b[0m output_video_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_video.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# Output video file name\u001b[39;00m\n\u001b[1;32m--> 215\u001b[0m processor \u001b[38;5;241m=\u001b[39m PackageDetectionProcessor(video_file, output_video_file\u001b[38;5;241m=\u001b[39moutput_video_file)\n\u001b[0;32m    216\u001b[0m processor\u001b[38;5;241m.\u001b[39mstart_processing()\n",
      "Cell \u001b[1;32mIn[2], line 49\u001b[0m, in \u001b[0;36mPackageDetectionProcessor.__init__\u001b[1;34m(self, video_file, yolo_model_path, output_video_file)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpackage_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropped_images_folder \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcropped_packages\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 49\u001b[0m os\u001b[38;5;241m.\u001b[39mmaked(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcropped_images_folder, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     51\u001b[0m \u001b[38;5;66;03m# Detection line parameters\u001b[39;00m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcx1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m416\u001b[39m  \u001b[38;5;66;03m# X-position of the vertical line\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'os' has no attribute 'maked'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralytics import YOLO\n",
    "import cvzone\n",
    "import base64\n",
    "import os\n",
    "import time\n",
    "import threading\n",
    "import pygame  # For playing alert sounds\n",
    "from openai import OpenAI\n",
    "\n",
    "# Initialize OpenAI client for OpenRouter.ai\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"\",  # Replace with your OpenRouter API key\n",
    ")\n",
    "\n",
    "class PackageDetectionProcessor:\n",
    "    def __init__(self, video_file, yolo_model_path=\"best.pt\", output_video_file=\"output_video.mp4\"):\n",
    "        \"\"\"Initialize package detection processor for conveyor belt monitoring.\"\"\"\n",
    "        try:\n",
    "            self.yolo_model = YOLO(yolo_model_path)\n",
    "            self.names = self.yolo_model.names\n",
    "        except Exception as e:\n",
    "            raise RuntimeError(f\"Error loading YOLO model: {e}\")\n",
    "\n",
    "        self.cap = cv2.VideoCapture(video_file)\n",
    "        if not self.cap.isOpened():\n",
    "            raise FileNotFoundError(\"Error: Could not open video file.\")\n",
    "\n",
    "        # Get video properties for VideoWriter\n",
    "        self.frame_width = int(self.cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        self.frame_height = int(self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        self.fps = int(self.cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "        # Initialize VideoWriter to save the output video\n",
    "        self.output_video_file = output_video_file\n",
    "        self.video_writer = cv2.VideoWriter(\n",
    "            self.output_video_file,\n",
    "            cv2.VideoWriter_fourcc(*'mp4v'),  # Codec for .mp4 files\n",
    "            self.fps,\n",
    "            (self.frame_width, self.frame_height)\n",
    "        )\n",
    "\n",
    "        self.processed_track_ids = set()\n",
    "        self.current_date = time.strftime(\"%Y-%m-%d\")\n",
    "        self.output_filename = f\"package_data_{self.current_date}.txt\"\n",
    "        self.cropped_images_folder = \"cropped_packages\"\n",
    "        os.maked(self.cropped_images_folder, exist_ok=True)\n",
    "\n",
    "        # Detection line parameters\n",
    "        self.cx1 = 416  # X-position of the vertical line\n",
    "        self.offset = 6  # Offset for detection tolerance\n",
    "\n",
    "        # Sound alert setup\n",
    "        pygame.mixer.init()\n",
    "        self.alert_sound = \"alert.mp3\"  # Ensure this file exists in the same directory\n",
    "        self.sound_playing = False  # Track sound state\n",
    "        \n",
    "        # Initialize report file\n",
    "        if not os.path.exists(self.output_filename):\n",
    "            with open(self.output_filename, \"w\", encoding=\"utf-8\") as file:\n",
    "                file.write(\"Timestamp | Track ID | Package Type | Front Open | Damage Condition\\n\")\n",
    "                file.write(\"-\" * 80 + \"\\n\")\n",
    "\n",
    "    def play_alert(self):\n",
    "        \"\"\"Play an alert sound if it's not already playing.\"\"\"\n",
    "        if not self.sound_playing:\n",
    "            pygame.mixer.music.load(self.alert_sound)\n",
    "            pygame.mixer.music.play(-1)  # Loop indefinitely\n",
    "            self.sound_playing = True\n",
    "\n",
    "    def stop_alert(self):\n",
    "        \"\"\"Stop the alert sound if playing.\"\"\"\n",
    "        if self.sound_playing:\n",
    "            pygame.mixer.music.stop()\n",
    "            self.sound_playing = False\n",
    "\n",
    "    def analyze_image_with_openai(self, image_path):\n",
    "        \"\"\"Analyze the package image using OpenAI via OpenRouter.ai.\"\"\"\n",
    "        try:\n",
    "            with open(image_path, \"rb\") as img_file:\n",
    "                base64_image = base64.b64encode(img_file.read()).decode(\"utf-8\")\n",
    "\n",
    "            # Prepare the prompt for OpenAI\n",
    "            prompt = \"\"\"\n",
    "            Analyze the given image of a package and extract the following details:\n",
    "            \n",
    "            - **Box Front Open (Yes/No)**\n",
    "            - **Damage Condition (Yes/No)**\n",
    "            \n",
    "            Return results in table format only:\n",
    "            | Package Type (box) | Box Front Flap Open (Yes/No) | Damage Condition (Yes/No) |\n",
    "            |--------------------|----------------------------|--------------------------|\n",
    "            \"\"\"\n",
    "\n",
    "            # Send the request to OpenAI via OpenRouter.ai\n",
    "            completion = client.chat.completions.create(\n",
    "                extra_headers={\n",
    "                    \"HTTP-Referer\": \"<YOUR_SITE_URL>\",  # Optional. Replace with your site URL.\n",
    "                    \"X-Title\": \"<YOUR_SITE_NAME>\",     # Optional. Replace with your site name.\n",
    "                },\n",
    "                extra_body={},\n",
    "                model=\"google/gemini-2.0-pro-exp-02-05:free\",  # Replace with your preferred model\n",
    "                messages=[\n",
    "                    {\n",
    "                        \"role\": \"user\",\n",
    "                        \"content\": [\n",
    "                            {\"type\": \"text\", \"text\": prompt},\n",
    "                            {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/jpeg;base64,{base64_image}\"}}\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            response_text = completion.choices[0].message.content.strip()\n",
    "            return response_text\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error invoking OpenAI model: {e}\")\n",
    "            return \"Error processing image.\"\n",
    "\n",
    "    def process_crop_image(self, image, track_id):\n",
    "        \"\"\"Save and analyze cropped package images.\"\"\"\n",
    "        timestamp = time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "        image_filename = os.path.join(self.cropped_images_folder, f\"package_{track_id}_{timestamp}.jpg\")\n",
    "        cv2.imwrite(image_filename, image)\n",
    "\n",
    "        response_content = self.analyze_image_with_openai(image_filename)\n",
    "        extracted_data = response_content.split(\"\\n\")[2:]\n",
    "\n",
    "        alert_triggered = False  # Flag to track if an alert is needed\n",
    "        \n",
    "        if extracted_data:\n",
    "            with open(self.output_filename, \"a\", encoding=\"utf-8\") as file:\n",
    "                for row in extracted_data:\n",
    "                    if \"--------------\" in row or not row.strip():\n",
    "                        continue\n",
    "                    values = [col.strip() for col in row.split(\"|\")[1:-1]]\n",
    "                    if len(values) == 3:\n",
    "                        package_type, box_open, damage_status = values\n",
    "                        file.write(f\"{timestamp} | Track ID: {track_id} | {package_type} | {box_open} | {damage_status}\\n\")\n",
    "                        \n",
    "                        if box_open.lower() == \"yes\":\n",
    "                            alert_triggered = True  # Trigger alert\n",
    "\n",
    "        if alert_triggered:\n",
    "            self.play_alert()\n",
    "        else:\n",
    "            self.stop_alert()\n",
    "\n",
    "    def crop_and_process(self, frame, box, track_id):\n",
    "        \"\"\"Crop and process detected packages.\"\"\"\n",
    "        if track_id in self.processed_track_ids:\n",
    "            return  \n",
    "\n",
    "        x1, y1, x2, y2 = map(int, box)\n",
    "        cropped_image = frame[y1:y2, x1:x2]\n",
    "        self.processed_track_ids.add(track_id)\n",
    "        threading.Thread(target=self.process_crop_image, args=(cropped_image, track_id), daemon=True).start()\n",
    "\n",
    "    def process_video_frame(self, frame):\n",
    "        \"\"\"Process each video frame to detect and analyze packages.\"\"\"\n",
    "        frame = cv2.resize(frame, (1020, 600))\n",
    "        results = self.yolo_model.track(frame, persist=True)\n",
    "\n",
    "        if results and results[0].boxes is not None:\n",
    "            boxes = results[0].boxes.xyxy.int().cpu().tolist()\n",
    "            track_ids = results[0].boxes.id.int().cpu().tolist() if results[0].boxes.id is not None else [-1] * len(boxes)\n",
    "\n",
    "            for box, track_id in zip(boxes, track_ids):\n",
    "                x1, y1, x2, y2 = map(int, box)\n",
    "                cx = (x1 + x2) // 2 \n",
    "                if self.cx1 - self.offset < cx < self.cx1 + self.offset:\n",
    "                    cv2.rectangle(frame, (x1, y1), (x2, y2), (255, 0, 255), 2)\n",
    "                    cvzone.putTextRect(frame, f\"ID: {track_id}\", (x2, y2), 1, 1)\n",
    "                    self.crop_and_process(frame, box, track_id)\n",
    "        return frame\n",
    "\n",
    "    @staticmethod\n",
    "    def mouse_callback(event, x, y, flags, param):\n",
    "        if event == cv2.EVENT_MOUSEMOVE:\n",
    "            print(f\"Mouse Position: ({x}, {y})\")\n",
    "\n",
    "    def start_processing(self):\n",
    "        cv2.namedWindow(\"Package Detection\")\n",
    "        cv2.setMouseCallback(\"Package Detection\", self.mouse_callback)\n",
    "\n",
    "        \"\"\"Start video processing.\"\"\"\n",
    "        while self.cap.isOpened():\n",
    "            ret, frame = self.cap.read()\n",
    "            if not ret:\n",
    "                self.stop_alert()\n",
    "                break\n",
    "\n",
    "            # Process the frame\n",
    "            processed_frame = self.process_video_frame(frame)\n",
    "\n",
    "            # Write the processed frame to the output video\n",
    "            self.video_writer.write(processed_frame)\n",
    "\n",
    "            # Display the processed frame\n",
    "            cv2.imshow(\"Package Detection\", processed_frame)\n",
    "            if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                break\n",
    "\n",
    "        # Release resources\n",
    "        self.cap.release()\n",
    "        self.video_writer.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        print(f\"✅ Processing completed. Output video saved to {self.output_video_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    video_file = \"co.mp4\"\n",
    "    output_video_file = \"output_video.mp4\"  # Output video file name\n",
    "    processor = PackageDetectionProcessor(video_file, output_video_file=output_video_file)\n",
    "    processor.start_processing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846f2738-8db7-4e74-b628-26a3e19a23b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
